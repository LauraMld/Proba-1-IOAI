# -*- coding: utf-8 -*-
"""NitroNou.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pNMqWpnoIUSWi_xeRUtQTNH97iBaJlsD
"""

from google.colab import files
files.upload()

import os
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
!kaggle competitions download -c nitro-language-processing-3
!unzip nitro-language-processing-3.zip -d nitro

import pandas as pd
import re
import nltk
from nltk.corpus import stopwords
from nltk.stem.snowball import SnowballStemmer

nltk.download('stopwords')

# Load data
df = pd.read_csv('nitro/train.csv')

# Print column names to verify
print(df.columns)

# Check if 'class' column exists
if 'class' not in df.columns:
    raise KeyError("Column 'class' not found in the dataset!")

# Text Preprocessing Function for Romanian
def preprocess_text(text):
    text = re.sub(r'<.*?>', '', text)  # Remove HTML tags
    text = re.sub(r'http\S+|www\S+|https\S+', '', text, flags=re.MULTILINE)  # Remove URLs
    text = re.sub(r'\@w+|\#', '', text)  # Remove mentions and hashtags
    text = re.sub(r'[^a-zA-ZăîâșțĂÎÂȘȚ\s]', '', text)  # Remove special characters and numbers
    text = text.lower()  # Convert to lowercase
    text = text.split()
    stemmer = SnowballStemmer("romanian")
    text = [stemmer.stem(word) for word in text if word not in stopwords.words('romanian')]
    return ' '.join(text)

# Apply preprocessing
df['title'] = df['title'].fillna('')
df['content'] = df['content'].fillna('')
df['text'] = df['title'] + ' ' + df['content']
df['text'] = df['text'].apply(preprocess_text)

# Check the DataFrame after preprocessing
print(df.head())

# Check the class column
print(df['class'].unique())

import matplotlib.pyplot as plt
from wordcloud import WordCloud

# Word Cloud
text = ' '.join(df['text'])
wordcloud = WordCloud(width=800, height=400, max_font_size=110, collocations=False).generate(text)

plt.figure(figsize=(15, 8))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.show()

# Class Distribution
df['class'].value_counts().plot(kind='bar')
plt.title('Class Distribution')
plt.show()

from sklearn.feature_extraction.text import TfidfVectorizer

# TF-IDF Vectorization
vectorizer = TfidfVectorizer(max_features=10000)
X = vectorizer.fit_transform(df['text'])
y = df['class']

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score

# Split data
X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)

# Random Forest Classifier
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)
y_pred = rf_model.predict(X_val)
accuracy = accuracy_score(y_val, y_pred)
print(f'Random Forest Validation Accuracy: {accuracy}')

# Evaluate the Random Forest model on the validation set
y_pred = rf_model.predict(X_val)
accuracy = accuracy_score(y_val, y_pred)
print(f'Random Forest Validation Accuracy: {accuracy}')

# Load test data
test_df = pd.read_csv('nitro/test.csv')

# Apply preprocessing to the test data
test_df['title'] = test_df['title'].fillna('')
test_df['content'] = test_df['content'].fillna('')
test_df['text'] = test_df['title'] + ' ' + test_df['content']
test_df['text'] = test_df['text'].apply(preprocess_text)

# Transform the test data using the same vectorizer
X_test = vectorizer.transform(test_df['text'])

# Predict on the test data
test_preds = rf_model.predict(X_test)

# Create submission DataFrame
submission_df = pd.DataFrame({'id': test_df.index, 'label': test_preds})

# Save to CSV
submission_df.to_csv('nitro/submission.csv', index=False)
print('Submission file created successfully!')

files.download('nitro/submission.csv')