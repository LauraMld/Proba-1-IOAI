# -*- coding: utf-8 -*-
"""nitro.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Cx0cD1JNqjBLQu00Y2x-5vEPcRJ2XoUZ
"""

# Install kaggle CLI if not installed
!pip install kaggle

# Make sure to have kaggle.json in the right directory before running this cell
file.upload()
!mkdir -p ~/.kaggle
!mv kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

# Download the competition data
!kaggle competitions download -c nitro-language-processing-3

# Unzip the downloaded files
!unzip nitro-language-processing-3.zip -d nitro-language-processing-3

# Import libraries
import pandas as pd
import numpy as np
import tensorflow as tf
from transformers import BertTokenizer, TFBertForSequenceClassification
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report

# Setting the random seed for reproducibility
import random_seed_setter
random_seed_setter.set_seed(42)

# Load datasets
train_df = pd.read_csv('nitro-language-processing-3/train.csv')
test_df = pd.read_csv('nitro-language-processing-3/test.csv')

# Fill missing title or content with empty strings
train_df['title'] = train_df['title'].fillna('')
train_df['content'] = train_df['content'].fillna('')

# Combine title and content
train_df['text'] = train_df['title'] + ' ' + train_df['content']

# Process the same for the test set
test_df['title'] = test_df['title'].fillna('')
test_df['content'] = test_df['content'].fillna('')
test_df['text'] = test_df['title'] + ' ' + test_df['content']

# Load BERT tokenizer
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')

# Tokenize data
train_encodings = tokenizer(train_df['text'].tolist(), truncation=True, padding=True, max_length=128)
test_encodings = tokenizer(test_df['text'].tolist(), truncation=True, padding=True, max_length=128)

# Create labels
train_labels = train_df['label'].values

# Convert to TensorFlow dataset
train_dataset = tf.data.Dataset.from_tensor_slices((
    dict(train_encodings),
    train_labels
)).shuffle(len(train_df)).batch(16)

# Create dataset for test set (without labels)
test_dataset = tf.data.Dataset.from_tensor_slices((
    dict(test_encodings)
)).batch(16)

# Load BERT model
model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)

# Compile the model
model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5),
              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),
              metrics=['accuracy'])

# Train the model
model.fit(train_dataset, epochs=3)

# Predict on test set
test_predictions = model.predict(test_dataset).logits
test_predictions = tf.argmax(test_predictions, axis=1).numpy()

# Create submission file
submission_df = pd.DataFrame({'id': test_df['id'], 'label': test_predictions})
submission_df.to_csv('submission.csv', index=False)

# Ensure the submission file is in the correct format
submission = pd.read_csv('submission.csv')
print(submission.head())