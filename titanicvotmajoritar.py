# -*- coding: utf-8 -*-
"""TitanicVotMajoritar.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nusLREp_BtmWoMXW3LHOxUoBBxWsV-EG
"""

from google.colab import files
files.upload()

import os
!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
!kaggle competitions download -c titanic
!unzip titanic.zip -d titanic

# Importăm librăriile necesare
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import accuracy_score

# Încărcăm și preprocesăm datele (similar cu pașii anteriori)
train_df = pd.read_csv('titanic/train.csv')
test_df = pd.read_csv('titanic/test.csv')
train_df.head()
train_df.info()
train_df.describe()
train_df = train_df.drop(['Ticket', 'Cabin'], axis=1)
test_df = test_df.drop(['Ticket', 'Cabin'], axis=1)

# Umplem valorile lipsă pentru 'Age' și 'Embarked'
train_df['Age'].fillna(train_df['Age'].median(), inplace=True)
test_df['Age'].fillna(test_df['Age'].median(), inplace=True)

train_df['Embarked'].fillna(train_df['Embarked'].mode()[0], inplace=True)
test_df['Embarked'].fillna(test_df['Embarked'].mode()[0], inplace=True)

test_df['Fare'].fillna(test_df['Fare'].median(), inplace=True)

train_df['Sex'] = train_df['Sex'].map({'male': 0, 'female': 1})
test_df['Sex'] = test_df['Sex'].map({'male': 0, 'female': 1})

train_df['Embarked'] = train_df['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})
test_df['Embarked'] = test_df['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})

X_train = train_df.drop(['Survived', 'Name', 'PassengerId'], axis=1)
y_train = train_df['Survived']
X_test = test_df.drop(['Name', 'PassengerId'], axis=1)

# Împărțim datele în seturi de antrenament și test
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)

# Definim și antrenăm mai multe modele
# Logistic Regression
lr = LogisticRegression(random_state=42, max_iter=1000)
lr.fit(X_train, y_train)
lr_pred = lr.predict(X_val)
print("Logistic Regression Accuracy:", accuracy_score(y_val, lr_pred))

# Support Vector Machine
svc = SVC(random_state=42)
svc.fit(X_train, y_train)
svc_pred = svc.predict(X_val)
print("Support Vector Machine Accuracy:", accuracy_score(y_val, svc_pred))

# Random Forest
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X_train, y_train)
rf_pred = rf.predict(X_val)
print("Random Forest Accuracy:", accuracy_score(y_val, rf_pred))

# Gradient Boosting
gb = GradientBoostingClassifier(random_state=42)
gb.fit(X_train, y_train)
gb_pred = gb.predict(X_val)
print("Gradient Boosting Accuracy:", accuracy_score(y_val, gb_pred))

# Combinăm predicțiile (ensemble) folosind un vot majoritar
predictions = np.array([lr_pred, svc_pred, rf_pred, gb_pred])
ensemble_pred = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)
print("Ensemble Accuracy:", accuracy_score(y_val, ensemble_pred))

test_predictions = np.array([lr.predict(X_test), svc.predict(X_test), rf.predict(X_test), gb.predict(X_test)])
ensemble_test_pred = np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=test_predictions)

output = pd.DataFrame({'PassengerId': test_df['PassengerId'], 'Survived': ensemble_test_pred})
output.to_csv('ensemble_submission.csv', index=False)
print("Submission file saved as 'ensemble_submission.csv'.")

files.download('ensemble_submission.csv')