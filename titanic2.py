# -*- coding: utf-8 -*-
"""Titanic2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nZ6MNk7Bi-ED6m-Do60Vk0yu-H2yPCQN
"""

# Configurare Colab pentru a accesa Kaggle
from google.colab import files
files.upload()  # Încarcă kaggle.json

import os
os.makedirs('/root/.kaggle/', exist_ok=True)
!mv kaggle.json /root/.kaggle/
!chmod 600 /root/.kaggle/kaggle.json

# Descărcare date de pe Kaggle
!kaggle competitions download -c titanic
!unzip titanic.zip -d titanic

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
# %matplotlib inline

train_df = pd.read_csv('titanic/train.csv')
test_df = pd.read_csv('titanic/test.csv')

# Explorare inițială
print(train_df.head())
print(train_df.info())
print(train_df.describe())

# Eliminare coloane irelevante
train_df.drop(['Ticket', 'Cabin'], axis=1, inplace=True)
test_df.drop(['Ticket', 'Cabin'], axis=1, inplace=True)

# Umplerea valorilor lipsă
train_df['Age'].fillna(train_df['Age'].median(), inplace=True)
test_df['Age'].fillna(test_df['Age'].median(), inplace=True)

train_df['Embarked'].fillna(train_df['Embarked'].mode()[0], inplace=True)
test_df['Embarked'].fillna(test_df['Embarked'].mode()[0], inplace=True)

test_df['Fare'].fillna(test_df['Fare'].median(), inplace=True)

# Creare Family Size
train_df['Family_Size'] = train_df['SibSp'] + train_df['Parch'] + 1
test_df['Family_Size'] = test_df['SibSp'] + test_df['Parch'] + 1

# Extrage titlurile din coloana Name
train_df['Title'] = train_df['Name'].str.extract(' ([A-Za-z]+)\.', expand=False)
test_df['Title'] = test_df['Name'].str.extract(' ([A-Za-z]+)\.', expand=False)

# Maparea titlurilor rare la "Rare"
rare_titles = ['Lady', 'Countess', 'Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona']
train_df['Title'] = train_df['Title'].replace(rare_titles, 'Rare')
test_df['Title'] = test_df['Title'].replace(rare_titles, 'Rare')

# Maparea titlurilor în categorii numerice
title_mapping = {'Mr': 1, 'Miss': 2, 'Mrs': 3, 'Master': 4, 'Rare': 5}
train_df['Title'] = train_df['Title'].map(title_mapping)
train_df['Title'] = train_df['Title'].fillna(0)
test_df['Title'] = test_df['Title'].map(title_mapping)
test_df['Title'] = test_df['Title'].fillna(0)

# Calcularea medianei vârstei pentru fiecare titlu
title_age_median = train_df.groupby('Title')['Age'].median()

# Funcție pentru completarea vârstei lipsă pe baza titlului
def fill_age(row, median_dict):
    if pd.isnull(row['Age']):
        return median_dict[row['Title']]
    else:
        return row['Age']

# Aplicarea funcției pentru completarea vârstei lipsă în setul de date de antrenament
train_df['Age'] = train_df.apply(lambda row: fill_age(row, title_age_median), axis=1)

# Aplicarea funcției pentru completarea vârstei lipsă în setul de date de test
test_df['Age'] = test_df.apply(lambda row: fill_age(row, title_age_median), axis=1)

# Binning pentru Fare
train_df['FareBin'] = pd.qcut(train_df['Fare'], 4, labels=[1, 2, 3, 4])
test_df['FareBin'] = pd.qcut(test_df['Fare'], 4, labels=[1, 2, 3, 4])

# Convertirea variabilelor categorice
train_df['Sex'] = train_df['Sex'].map({'male': 0, 'female': 1})
test_df['Sex'] = test_df['Sex'].map({'male': 0, 'female': 1})

train_df['Embarked'] = train_df['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})
test_df['Embarked'] = test_df['Embarked'].map({'S': 0, 'C': 1, 'Q': 2})

X = train_df.drop(['Survived', 'Name', 'PassengerId'], axis=1)
y = train_df['Survived']
X_test = test_df.drop(['Name', 'PassengerId'], axis=1)

# Antrenarea modelului Logistic Regression
logreg = LogisticRegression(max_iter=1000)
logreg.fit(X, y)

# Validare încrucișată
cv_scores = cross_val_score(logreg, X, y, cv=5)
print(f'Logistic Regression CV scores: {cv_scores}')
print(f'Average CV score: {np.mean(cv_scores)}')

# Antrenarea modelului Random Forest
rf = RandomForestClassifier(n_estimators=100, random_state=42)
rf.fit(X, y)

# Validare încrucișată
cv_scores = cross_val_score(rf, X, y, cv=5)
print(f'Random Forest CV scores: {cv_scores}')
print(f'Average CV score: {np.mean(cv_scores)}')

# Antrenarea modelului Gradient Boosting
gb = GradientBoostingClassifier(n_estimators=100, random_state=42)
gb.fit(X, y)

# Validare încrucișată
cv_scores = cross_val_score(gb, X, y, cv=5)
print(f'Gradient Boosting CV scores: {cv_scores}')
print(f'Average CV score: {np.mean(cv_scores)}')

param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [3, 5, 7],
    'min_samples_split': [2, 5, 10],
    'min_samples_leaf': [1, 2, 4]
}

grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)
grid_search.fit(X, y)

print(f'Best parameters: {grid_search.best_params_}')
print(f'Best score: {grid_search.best_score_}')

# Utilizarea celui mai bun model pentru predicții
best_model = grid_search.best_estimator_
predictions = best_model.predict(X_test)

# Salvarea predicțiilor în fișier CSV
output = pd.DataFrame({'PassengerId': test_df['PassengerId'], 'Survived': predictions})
output.to_csv('submission.csv', index=False)
print("Submission saved!")

files.download('submission.csv')